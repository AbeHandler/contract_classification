{
 "metadata": {
  "name": "",
  "signature": "sha256:9e517767e217237742cc343d7986b98de3f2d0575d4a7407fe3210024809bce1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "This tutorial helped me implement the classifier: http://nbviewer.ipython.org/github/gmonce/scikit-learn-book/blob/master/Chapter%202%20-%20Supervised%20Learning%20-%20Text%20Classification%20with%20Naive%20Bayes.ipynb\n",
      "\n",
      "%pylab inline\n",
      "import IPython\n",
      "import sklearn as sk\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['clf', 'split']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#run main.sh at the start to get the data from Charlie + do some preprocessing\n",
      "from glob import glob\n",
      "import os\n",
      "CORPUS_LOCATION = \"/Volumes/usb/\" \n",
      "contracts = glob(CORPUS_LOCATION + \"*_text*\") \n",
      "labeled_data = [l.replace(\"\\n\", \"\") for l in open(\"labels.csv\")]\n",
      "labeled_data = [(l.split(\",\")[0],l.split(\",\")[1])  for l in labeled_data]\n",
      "\n",
      "def get_contract_text(label):\n",
      "    contract_lines = [l.replace(\"\\\\n\", \"\") for l in open(label)]\n",
      "    contract_lines = \" \".join(contract_lines)\n",
      "    return contract_lines\n",
      "\n",
      "def exists_in_corpus(label):\n",
      "    return os.path.exists(CORPUS_LOCATION + label + \"_text.txt\")\n",
      "\n",
      "all_texts = [get_contract_text(c) for c in contracts]\n",
      "labeled_data = [l for l in labeled_data if exists_in_corpus(l[0])]\n",
      "labels = [l[1] for l in labeled_data]\n",
      "texts = [get_contract_text(CORPUS_LOCATION + l[0] + \"_text.txt\") for l in labeled_data]\n",
      "contract_nos = [l[0] for l in labeled_data]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "from scipy.stats import sem\n",
      "\n",
      "def evaluate_cross_validation(clf, X, y, K):\n",
      "    # create a k-fold croos validation iterator of k=5 folds\n",
      "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
      "    # by default the score used is the one returned by score method of the estimator (accuracy)\n",
      "    scores = cross_val_score(clf, X, y, cv=cv)\n",
      "    print scores\n",
      "    print (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
      "        np.mean(scores), sem(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn import tree\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
      "\n",
      "stop_words = [w for w in nltk.corpus.stopwords.words('english')]\n",
      "stop_words.append(\"New\")\n",
      "stop_words.append(\"Orleans\")\n",
      "stop_words.append(\"City\")\n",
      "\n",
      "\n",
      "stop_words = set([w for w in nltk.corpus.stopwords.words('english')])\n",
      "\n",
      "clf_1 = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_2 = Pipeline([\n",
      "    ('vect', HashingVectorizer(non_negative=True)),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_3 = Pipeline([\n",
      "    ('vect', TfidfVectorizer()),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_4 = Pipeline([\n",
      "    ('vect', TfidfVectorizer(\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
      "    )),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_5 = Pipeline([\n",
      "    ('vect', CountVectorizer(\n",
      "                stop_words=stop_words,\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",    \n",
      "    )),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_6 = Pipeline([\n",
      "    ('vect', CountVectorizer(\n",
      "                stop_words=stop_words,\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",    \n",
      "    )),\n",
      "    ('clf', MultinomialNB(alpha=0.01)),\n",
      "])\n",
      "clf_7 = Pipeline([\n",
      "    ('vect', CountVectorizer(\n",
      "                stop_words=stop_words,\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",    \n",
      "    )),\n",
      "    ('clf', MultinomialNB(alpha=0.03)),\n",
      "])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clfs = [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6, clf_7]\n",
      "for clf in clfs:\n",
      "    evaluate_cross_validation(clf, texts, labels, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.75555556  0.71375465]\n",
        "Mean score: 0.735 (+/-0.021)\n",
        "[ 0.51481481  0.72862454]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.622 (+/-0.107)\n",
        "[ 0.73333333  0.66542751]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.699 (+/-0.034)\n",
        "[ 0.74814815  0.67657993]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.712 (+/-0.036)\n",
        "[ 0.78148148  0.75464684]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.768 (+/-0.013)\n",
        "[ 0.81481481  0.85501859]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.835 (+/-0.020)\n",
        "[ 0.81481481  0.85501859]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.835 (+/-0.020)\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_7.fit(texts, labels)\n",
      "y_pred = clf_7.predict(all_texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#run main.sh at the start to get the data from Charlie + do some preprocessing\n",
      "from glob import glob\n",
      "import os\n",
      "import csv\n",
      "\n",
      "labeled_data = []\n",
      "extractor_strings = []\n",
      "extractor_strings_labels = []\n",
      "unknown_data_contract_ids = []\n",
      "unknown_data = []\n",
      "\n",
      "with open(\"amounts.csv\", 'rb') as csvfile:\n",
      "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
      "    for row in spamreader:\n",
      "        labeled_data.append((row[0], row[1], row[2]))\n",
      "        extractor_strings.append(row[1])\n",
      "        extractor_strings_labels.append(row[2])\n",
      "\n",
      "\n",
      "with open(\"amounts_unknown.csv\", 'rb') as csvfile:\n",
      "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
      "    for row in spamreader:\n",
      "        unknown_data.append(row[1])\n",
      "        unknown_data_contract_ids.append(row[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clfs = [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6, clf_7]\n",
      "for clf in clfs:\n",
      "    evaluate_cross_validation(clf, extractor_strings, extractor_strings_labels, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'evaluate_cross_validation' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-db5723199a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclf_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluate_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor_strings_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'evaluate_cross_validation' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_7.fit(extractor_strings, extractor_strings_labels)\n",
      "y_pred = clf_7.predict(unknown_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in range(0,len(unknown_data)):\n",
      "    if str(y_pred[p]) == 't' and not \"per\" in unknown_data[p] and not \"insurance\" in unknown_data[p].lower():\n",
      "        print unknown_data[p]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}