{
 "metadata": {
  "name": "",
  "signature": "sha256:e4a57c4d335ff83be955175af9375df5aea43a9252e596bb4ea2a51af131e7ab"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "This tutorial helped me implement the classifier: http://nbviewer.ipython.org/github/gmonce/scikit-learn-book/blob/master/Chapter%202%20-%20Supervised%20Learning%20-%20Text%20Classification%20with%20Naive%20Bayes.ipynb\n",
      "\n",
      "%pylab inline\n",
      "import IPython\n",
      "import sklearn as sk\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['clf', 'split']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#run main.sh at the start to get the data from Charlie + do some preprocessing\n",
      "from glob import glob\n",
      "import os\n",
      "CORPUS_LOCATION = \"/Volumes/usb/\" \n",
      "contracts = glob(CORPUS_LOCATION + \"*_text*\") \n",
      "labeled_data = [l.replace(\"\\n\", \"\") for l in open(\"labels.csv\")]\n",
      "labeled_data = [(l.split(\",\")[0],l.split(\",\")[1])  for l in labeled_data]\n",
      "\n",
      "def get_contract_text(label):\n",
      "    contract_lines = [l.replace(\"\\\\n\", \"\") for l in open(label)]\n",
      "    contract_lines = \" \".join(contract_lines)\n",
      "    return contract_lines\n",
      "\n",
      "def exists_in_corpus(label):\n",
      "    return os.path.exists(CORPUS_LOCATION + label + \"_text.txt\")\n",
      "\n",
      "all_texts = [get_contract_text(c) for c in contracts]\n",
      "labeled_data = [l for l in labeled_data if exists_in_corpus(l[0])]\n",
      "labels = [l[1] for l in labeled_data]\n",
      "texts = [get_contract_text(CORPUS_LOCATION + l[0] + \"_text.txt\") for l in labeled_data]\n",
      "contract_nos = [l[0] for l in labeled_data]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "from scipy.stats import sem\n",
      "\n",
      "def evaluate_cross_validation(clf, X, y, K):\n",
      "    # create a k-fold croos validation iterator of k=5 folds\n",
      "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
      "    # by default the score used is the one returned by score method of the estimator (accuracy)\n",
      "    scores = cross_val_score(clf, X, y, cv=cv)\n",
      "    print scores\n",
      "    print (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
      "        np.mean(scores), sem(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn import tree\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
      "\n",
      "stop_words = [w for w in nltk.corpus.stopwords.words('english')]\n",
      "stop_words.append(\"New\")\n",
      "stop_words.append(\"Orleans\")\n",
      "stop_words.append(\"City\")\n",
      "\n",
      "\n",
      "stop_words = set([w for w in nltk.corpus.stopwords.words('english')])\n",
      "\n",
      "clf_1 = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_2 = Pipeline([\n",
      "    ('vect', HashingVectorizer(non_negative=True)),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_3 = Pipeline([\n",
      "    ('vect', TfidfVectorizer()),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_4 = Pipeline([\n",
      "    ('vect', TfidfVectorizer(\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
      "    )),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_5 = Pipeline([\n",
      "    ('vect', CountVectorizer(\n",
      "                stop_words=stop_words,\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",    \n",
      "    )),\n",
      "    ('clf', MultinomialNB()),\n",
      "])\n",
      "clf_6 = Pipeline([\n",
      "    ('vect', CountVectorizer(\n",
      "                stop_words=stop_words,\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",    \n",
      "    )),\n",
      "    ('clf', MultinomialNB(alpha=0.01)),\n",
      "])\n",
      "clf_7 = Pipeline([\n",
      "    ('vect', CountVectorizer(\n",
      "                stop_words=stop_words,\n",
      "                token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",    \n",
      "    )),\n",
      "    ('clf', MultinomialNB(alpha=0.03)),\n",
      "])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clfs = [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6, clf_7]\n",
      "for clf in clfs:\n",
      "    evaluate_cross_validation(clf, texts, labels, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.75555556  0.71375465]\n",
        "Mean score: 0.735 (+/-0.021)\n",
        "[ 0.51481481  0.72862454]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.622 (+/-0.107)\n",
        "[ 0.73333333  0.66542751]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.699 (+/-0.034)\n",
        "[ 0.74814815  0.67657993]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.712 (+/-0.036)\n",
        "[ 0.78148148  0.75464684]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.768 (+/-0.013)\n",
        "[ 0.81481481  0.85501859]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.835 (+/-0.020)\n",
        "[ 0.81481481  0.85501859]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean score: 0.835 (+/-0.020)\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_7.fit(texts, labels)\n",
      "y_pred = clf_7.predict(all_texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print contracts[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Volumes/usb/1019447-downtown-development-district-contract-with-city_text.txt\n"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}